# chinese-llama-tokenizer

## 简介

以LLaMA-2的词表为基础，结合Baichuan对词表进行了扩充，提高中文编码效率。扩充后词表大小为57576，其中：

- 汉字21108个
- 词语5156条

用法：替换原来的分词器，并用中文语料增量训练LLaMA

## 效果

针对以下文本进行分词（运行test_tokenizer.py）：

```
    白日依山尽，黄河入海流。欲穷千里目，更上一层楼。
    好好好，这般的好；哈哈哈……
    黑龙江第十一辆比亚迪卖出——
    ```鮪鯀鯪鯽：~！￥（）【】、“”？—《》０１２３４５６７８９『』
    ### 上海市
    <table><tbody><tr><td></td></tr></tbody></table>
    The primary use of LLaMA is research on large language models...
    public static void main(String[] args) {
    \x80\u200e
```

结果：
> ['▁', '\n', '▁▁▁▁', '白', '日', '依', '山', '尽', '，', '黄河', '入', '海', '流', '。', '欲', '穷', '千里', '目', '，', '
> 更', '上', '一', '层', '楼', '。', '\n', '▁▁▁▁', '好', '好', '好', '，', '这', '般', '的', '好', '；', '哈', '哈', '
> 哈', '…', '…', '\n', '▁▁▁▁', '黑', '龙', '江', '第', '十', '一', '辆', '比', '亚', '迪', '卖', '出', '—', '—', '\n', '
> ▁▁▁', '▁```', '鮪', '鯀', '鯪', '鯽', '：', '~', '！', '￥', '（', '）', '【', '】', '、', '“', '”', '？', '—', '《', '》', '
> ０', '１', '２', '３', '４', '５', '６', '７', '８', '９', '『', '』', '\n', '▁▁▁', '▁###', '▁', '上海', '市', '\n', '▁▁▁', '
> ▁<', 'table', '><', 'tbody', '><', 'tr', '><', 'td', '></', 'td', '></', 'tr', '></', 'tbody', '></', 'table', '>', '
> \n', '▁▁▁', '▁The', '▁primary', '▁use', '▁of', '▁L', 'La', 'MA', '▁is', '▁research', '▁on', '▁large', '▁language', '
> ▁models', '...', '\n', '▁▁▁', '▁public', '▁static', '▁void', '▁main', '(', 'String', '[]', '▁args', ')', '▁{', '\n', '
> ▁▁▁▁', '\x80', '\u200e', '\n', '▁▁▁▁']

---

对比下LLaMA-2原版的分词结果：
> ['▁', '<0x0A>', '▁▁▁▁', '白', '日', '<0xE4>', '<0xBE>', '<0x9D>', '山', '<0xE5>', '<0xB0>', '<0xBD>', '，', '黄', '
> 河', '入', '海', '流', '。', '<0xE6>', '<0xAC>', '<0xB2>', '<0xE7>', '<0xA9>', '<0xB7>', '千', '里', '目', '，', '更', '
> 上', '一', '<0xE5>', '<0xB1>', '<0x82>', '<0xE6>', '<0xA5>', '<0xBC>', '。', '<0x0A>', '▁▁▁▁', '好', '好', '好', '，', '
> 这', '<0xE8>', '<0x88>', '<0xAC>', '的', '好', '；', '<0xE5>', '<0x93>', '<0x88>', '<0xE5>', '<0x93>', '<0x88>', '<
> 0xE5>', '<0x93>', '<0x88>', '…', '…', '<0x0A>', '▁▁▁▁', '<0xE9>', '<0xBB>', '<0x91>', '龙', '江', '第', '十', '一', '<
> 0xE8>', '<0xBE>', '<0x86>', '比', '<0xE4>', '<0xBA>', '<0x9A>', '<0xE8>', '<0xBF>', '<0xAA>', '<0xE5>', '<0x8D>', '<
> 0x96>', '出', '—', '—', '<0x0A>', '▁▁▁', '▁```', '<0xE9>', '<0xAE>', '<0xAA>', '<0xE9>', '<0xAF>', '<0x80>', '<
> 0xE9>', '<0xAF>', '<0xAA>', '<0xE9>', '<0xAF>', '<0xBD>', '：', '~', '！', '<0xEF>', '<0xBF>', '<
> 0xA5>', '（', '）', '【', '】', '、', '“', '”', '？', '—', '《', '》', '<0xEF>', '<0xBC>', '<0x90>', '１', '<0xEF>', '<
> 0xBC>', '<0x92>', '<0xEF>', '<0xBC>', '<0x93>', '<0xEF>', '<0xBC>', '<0x94>', '<0xEF>', '<0xBC>', '<0x95>', '<
> 0xEF>', '<0xBC>', '<0x96>', '<0xEF>', '<0xBC>', '<0x97>', '<0xEF>', '<0xBC>', '<0x98>', '<0xEF>', '<0xBC>', '<
> 0x99>', '『', '』', '<0x0A>', '▁▁▁', '▁###', '▁', '上', '海', '市', '<0x0A>', '▁▁▁', '▁<', 'table', '><', '
> tbody', '><', 'tr', '><', 'td', '></', 'td', '></', 'tr', '></', 'tbody', '></', 'table', '>', '<0x0A>', '▁▁▁', '
> ▁The', '▁primary', '▁use', '▁of', '▁L', 'La', 'MA', '▁is', '▁research', '▁on', '▁large', '▁language', '
> ▁models', '...', '<0x0A>', '▁▁▁', '▁public', '▁static', '▁void', '▁main', '(', 'String', '[]', '▁args', ')', '▁{', '<
> 0x0A>', '▁▁▁▁', '\x80', '\u200e', '<0x0A>', '▁▁▁▁']

可以看出，原版词表里的汉字太少。“白日依山尽”这么简单一句，就有“依”和“尽”不在词表里。

---

再对比下Baichuan的分词结果：
> ['▁', '\n', '▁▁▁▁', '白', '日', '依', '山', '尽', '，', '黄河', '入', '海', '流', '。', '欲', '穷', '千里', '目', '，', '
> 更', '上一', '层', '楼', '。', '\n', '▁▁▁▁', '好好', '好', '，', '这', '般', '的好', ';', '
> 哈哈哈', '.', '.', '.', '.', '.', '.', '\n', '▁▁▁▁', '黑龙江', '第十', '一辆', '比亚', '迪', '卖', '出', '——', '\n', '
> ▁▁▁▁', '```', '鮪', '鯀', '鯪', '鯽', '：', '~', '！', '￥', '()', '【', '】', '、', '“', '”', '？', '—', '《', '》', '０', '
> １', '２', '３', '４', '５', '６', '７', '８', '９', '『', '』', '\n', '▁▁▁▁', '###', '▁', '上海市', '尽', '头', '\n', '
> ▁▁▁▁', '\<table>', '\<tbody>', '\<tr>', '\<td>', '\</td>', '\</tr>', '\</tbody>', '\</table>', '\n', '▁▁▁▁', 'The', '
> ▁primary', '▁use', '▁of', '▁L', 'La', 'MA', '▁is', '▁research', '▁on', '▁large', '▁language', '
> ▁models', '.', '.', '.', '\n', '▁▁▁▁', 'public', '▁static', '▁void', '▁main', '(', 'String', '[]', '▁args', ')', '
> ▁{', '\n', '▁▁▁▁', '\x80', '▁', '\n', '▁▁▁▁']

可以看出，Baichuan对中文支持很好，编码高效。不过也存在可以优化的地方：

1. “更上一层楼”这句“上”和“一”结合到了一起
2. “好好好”拆成了“好好”和“好”
3. “第十一辆”拆成了“第十”和“一辆”
4. “比亚迪”拆成了“比亚”和“迪”
5. 省略号拆成了6个点

---

现在再回过头来看我们的结果，在最开始的地方。1-5我们没有发生。